\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{graphicx}
\geometry{margin=1in}

\title{Flash-SD-KDE}
\author{}
\date{}

\begin{document}
\maketitle

\section{Background}

Score-debiased kernel density estimation (SD-KDE) refines a standard kernel
density estimator by moving the data slightly in the direction of the score
function (the gradient of the log-density).  Given samples $x_i$ and a
bandwidth $h$, a Gaussian KDE is
\[
  \hat p(x)
  =
  \frac{1}{n h}
  \sum_{i=1}^n
  \varphi\!\left(\frac{x - x_i}{h}\right),
\]
and SD-KDE forms debiased samples
$x_i^{\mathrm{SD}} = x_i + \tfrac{h^2}{2}\,\hat s(x_i)$ where
$\hat s$ is an estimate of the score.  In this work we always use an
empirical score computed from the KDE itself, i.e.\ no parametric model
for the underlying density is assumed.  Writing $z_i(x) = (x - x_i)/h$ and
\[
  \hat p(x)
  =
  \frac{1}{n h}
  \sum_{i=1}^n
  \varphi\bigl(z_i(x)\bigr),
\]
we estimate the score as
\[
  \hat s(x)
  =
  \frac{\partial_x \hat p(x)}{\hat p(x)}
  =
  \frac{\sum_{i=1}^n \bigl[-z_i(x)\,\varphi(z_i(x))\bigr]}
       {h^2 \sum_{i=1}^n \varphi(z_i(x))}.
\]

\section{Task}

The goal of Flash-SD-KDE is to implement a fast, GPU-accelerated SD-KDE
(with empirical score) on an NVIDIA RTX~A6000 using Triton.  We:
\begin{itemize}
  \item implement a Gaussian KDE and KDE-based score estimator in Triton,
  \item use these to construct an empirical SD-KDE on the GPU, and
  \item benchmark against CPU Silverman KDE and scikit-learn's KDE over
        a range of sample sizes $(n_{\text{train}}, n_{\text{test}})$.
\end{itemize}

\subsection{Hardware}

All experiments run on a workstation equipped with an NVIDIA RTX~A6000
(GA102).  This GPU exposes 84 streaming multiprocessors (SMs); each SM
contains 128 FP32 ALUs and 16 special function units (SFUs).  Because the
ratio of FP32 ALUs to SFUs is $128{:}16$, we treat one $\exp$ (issued on an
SFU) as costing the equivalent of $128/16 = 8$ FP32 flops in our models.
The card delivers roughly $40$~TFLOP/s of peak FP32 throughput and
approximately $770$~GB/s of GDDR6 bandwidth.

The host CPU is a dual-socket AMD EPYC~7763 system (``Milan'') configured
with $2 \times 64$ cores and two hardware threads per core (256 logical
CPUs reported by \texttt{lscpu}).  The processors boost up to
3.53~GHz, expose 512~MiB of shared L3 cache across the sockets, and provide
modern ISA extensions (AVX/AVX2, FMA, BMI1/2, SHA, VAES, etc.).  Unless
otherwise noted, all CPU benchmarks in this report run on this platform.

\section{Arithmetic intensity of KDE}

Arithmetic intensity is defined as
\[
  I \;=\; \frac{\text{floating-point operations}}{\text{bytes moved to/from DRAM}}.
\]
For SD-KDE with $n_{\text{train}} = k$ and $n_{\text{test}} = k/8$,
there are two steps:
\begin{enumerate}
  \item \textbf{Score + shift:} For each training point we compute
        $\hat s(x_i)$ from all $k$ points and then form
        $x_i^{\mathrm{SD}} = x_i + \tfrac{h^2}{2}\hat s(x_i)$.  This uses
        $O(k^2)$ pairwise kernel interactions.  With the RTX~A6000 hardware
        ratio ($128$ FP32 ALUs, $16$ SFUs per SM) we budget an $\exp$ as
        $8$ flop-equivalents.  The score accumulation requires one $\exp$
        and roughly eight additional arithmetic ops (subtraction, scaling,
        accumulation), yielding $c_1 \approx 16$ flops per
        $(\text{train},\text{train})$ pair.
  \item \textbf{KDE on debiased samples:} We then evaluate a standard Gaussian
        KDE at $k/8$ query points using the $k$ debiased samples, which uses
        $O(k^2/8)$ interactions.  Each pair requires one $\exp$ (8 flops) plus
        about six other operations (difference, square, scaling, accumulation),
        so we take $c_2 \approx 14$ flops per $(\text{train},\text{test})$ pair.
\end{enumerate}
The total work is therefore approximated by
\[
  \text{FLOPs}(k)
  \;\approx\;
  c_1 k^2 + c_2\,k\,(k/8)
  \;\approx\;
  16 k^2 + 14\frac{k^2}{8}
  \;=\;
  17.75\,k^2.
\]
For $k = 32\text{k}$ this is on the order of
$2\times 10^{10}$ flops.  With a properly tiled GPU implementation, each training
point and each query can be loaded from global memory once and then reused
from registers or shared memory.  When we fix $n_{\text{test}} = k/8$ we move
\[
  \text{Bytes}(k) \approx 4\,(k + k/8 + k/8)
  = 4\Bigl(k + \frac{2k}{8}\Bigr)
  = 4\cdot\frac{5k}{4}
  = 5\,k
\]
bytes (counting one read of each train and test point and one write of each
output, up to lower-order terms).  The arithmetic intensity as a function of
$k$ is then
\[
  I(k)
  =
  \frac{\text{FLOPs}(k)}{\text{Bytes}(k)}
  \;\approx\;
  \frac{17.75\,k^2}{5\,k}
  \approx
  3.55\,k
  \quad \text{flops/byte}.
\]
This corresponds to the minimal traffic where each sample is read once and
each output is written once; any additional passes contributes only $O(k)$
more bytes and does not change the scaling.
Thus $I(k)$ grows linearly with $k$; for $k=32\text{k}$ this already yields
an intensity on the order of $1\times 10^5$ flops/byte, far above the
machine-balance point of the A6000, so the kernel is compute-bound rather
than bandwidth-bound.

For reference, the RTX~A6000 has a peak FP32 throughput of roughly
$40\,\text{TFLOP/s}$ and a memory bandwidth of about
$7.7\times 10^{11}$ bytes/s ($\approx 770\,\text{GB/s}$) from its GDDR6
memory (not HBM), corresponding to a balance point of
\[
  \frac{40\times 10^{12}}{7.7\times 10^{11}}
  \approx 50 \;\text{flops/byte}.
\]
Setting $I(k)\approx 3.55k \approx 50$ gives $k\approx 15$, so for any
realistic problem size (e.g.\ $k\ge 64$) SD-KDE on the A6000 is
firmly in the compute-bound regime.

\section{Empirical results}

We sweep $n_{\text{train}}$ over powers of two from $512$ to $32\text{k}$,
with $n_{\text{test}} = n_{\text{train}} / 8$, and average over three seeds.
For each configuration we record:
\begin{itemize}
  \item CPU Silverman KDE time,
  \item scikit-learn Gaussian KDE time, and
  \item SD-KDE GPU time.
\end{itemize}
Across the entire range, the empirical SD-KDE GPU implementation is
consistently faster than scikit-learn, with speedups growing with $n$; at
the largest sizes the GPU achieves well over an order-of-magnitude speedup
relative to the sklearn baseline.

For profiling and scaling studies we also introduce a Triton-only sweep over
larger problem sizes, using powers of two for $n_{\text{train}}$ up to
$2^{22} \approx 4.2$ million (and $n_{\text{test}} = n_{\text{train}}/8$) with
a single seed.  The helper script \texttt{run\_triton\_scaling.sh} executes
this experiment by invoking the \texttt{--emp-kernel-only} benchmark mode,
producing a compact log that we feed to Nsight Systems when examining the
multi-million-sample kernels.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\linewidth]{../flash-sd-kde.pdf}
  \caption{Average runtime (log-scale $y$-axis) of scikit-learn KDE and
           SD-KDE GPU across $n_{\text{train}}$; annotations show
           the SD-KDE GPU speedup relative to sklearn.}
  \label{fig:flash_sd_kde}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\linewidth]{../emp-sd-kde-util.pdf}
  \caption{Estimated GPU utilization (as a percentage of A6000 FP32 peak)
           for SD-KDE implemented in Triton and optimized Torch,
           computed from the flop model and the measured runtimes.}
  \label{fig:flash_sd_kde_util}
\end{figure}

\section{GPU utilization on A6000}

For $n_{\text{train}} = 32\text{k}$ and $n_{\text{test}} = 4\text{k}$, we
observe an average SD-KDE GPU runtime of approximately
$4\,\mathrm{ms}$.  There are
\[
  n_{\text{train}} \times n_{\text{test}}
  = 32{,}768 \times 4{,}096
  \approx 1.34 \times 10^8
\]
pairwise interactions contributing to the KDE stage, and an additional
$O(k^2)$ interactions for the empirical score.  Using the updated flop model
for SD-KDE (one $\exp$ counted as eight FP32 flops), this corresponds to roughly
$2\times 10^{10}$ flops.  Dividing
by the observed $4\,\mathrm{ms}$ runtime gives an empirical throughput on the
order of a few TFLOP/s.  The RTX~A6000 has a peak single-precision throughput
of about $40\,\text{TFLOP/s}$, so the achieved utilization is in the
single-digit percent range.
This modest utilization is expected for a first, straightforward Triton
implementation without extensive fusion or kernel tuning; nonetheless, the
kernel already delivers substantial end-to-end speedups over the CPU and
sklearn baselines while leaving significant headroom for further optimization.

\section{Large-scale experiments}

To stress-test the Triton implementation beyond the sweep shown in
Figure~\ref{fig:flash_sd_kde}, we run a Triton-only experiment that scales
$n_{\text{train}}$ over powers of two from $2^{15}$ through $2^{22}$
($\approx 4.2$ million), keeping $n_{\text{test}} = n_{\text{train}}/8$
and using a single seed.  We invoke \texttt{benchmark\_triton\_kde.py}
with \texttt{--emp-kernel-only} so the profile captures just the score,
shift, and final KDE kernels, and we record the runtime for each size.
Using the same flop model that underlies Figure~\ref{fig:flash_sd_kde_util}, we
convert the runtimes into an estimated percentage of the A6000 FP32 peak.
Figure~\ref{fig:triton_large_util} summarizes the resulting utilization curve.
Even at $n_{\text{train}} \approx 4$ million the kernel remains comfortably
compute-bound, though the achieved utilization is still in the low
double-digit percentages, highlighting ample room for further kernel
fusion and occupancy tuning at the largest scales.

\subsection*{16-D SD-KDE utilization}

We also profile the full 16-D SD-KDE pipeline (score + shift + KDE) using the
Tensor-Core kernels introduced earlier.  Let $n$ denote the number of training
samples and $m$ the number of query points (fixed to $n/8$ in our sweep).
The empirical SD-KDE consists of three high-cost stages:
\begin{enumerate}
  \item $\mathbf{G} = \mathbf{X}\mathbf{X}^\top$ to form pairwise dot-products
        ($2 d n^2$ flops with $d = 16$),
  \item $\mathbf{T} = \Phi \mathbf{X}$, where $\Phi_{ij} =
        \exp(-\lVert x_i - x_j\rVert^2 / 2h^2)$, to accumulate the
        $\sum_j \varphi_{ij} y_j$ numerator ($2 d n^2$ flops plus
        $4 n^2$ scalar FLOPs for norms and distance terms and $8 n^2$
        FLOPs from the SFUs executing exponentials), and
  \item $\mathbf{Q} = \tilde{\mathbf{X}}\mathbf{Y}^\top$ for the final KDE on
        the debiased samples ($2 d m n$ flops plus $4 m n$ scalar FLOPs for
        norms/distances and $8 m n$ FLOPs from the exponentials).
\end{enumerate}
Aggregating these terms yields the flop model used for Figure~\ref{fig:triton_sd_kde_nd_util}:
\[
  \text{FLOPs}_{16\text{D}}
  \approx 4 d n^2 + (4 + 8) n^2 + 2 d m n + (4 + 8) m n
  \qquad (d = 16,\; m = n/8),
\]
where each exponential is counted as 8 FLOPs because the SFU throughput is
1/8 of the FP32 ALU throughput on the RTX~A6000.
Figure~\ref{fig:triton_sd_kde_nd_util} compares the resulting utilization for
the Torch GEMM baseline and the Triton Tensor-Core implementation across
powers of two up to $n = 32{,}768$.  Torch remains limited by SIMT FP32
throughput and therefore tops out in the single-digit range, whereas Triton
consistently achieves multi-digit utilization by mapping both GEMMs to Tensor
Cores, even though each problem entails 16 times more arithmetic than the 1-D
setting.  Figure~\ref{fig:nd_runtime} provides the corresponding runtime
comparison, highlighting the gap between sklearn, the Torch SD-KDE baseline,
and the Triton SD-KDE implementation.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\linewidth]{../nd-runtime.pdf}
  \caption{Runtime comparison for 16-D KDE/SD-KDE across $n_{\text{train}}$
           up to $32{,}768$ ($n_{\text{test}} = n_{\text{train}}/8$).
           The Triton SD-KDE enjoys both the Tensor-Core acceleration
           (relative to sklearn) and the GEMM-based score computation
           (relative to the Torch baseline).}
  \label{fig:nd_runtime}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\linewidth]{../triton-sd-kde-nd-util.pdf}
  \caption{Utilization (percentage of RTX A6000 FP32 peak) for the 16-D SD-KDE
           pipeline, using the flop estimate
           $4 d n^2 + 6 n^2 + 2 d m n + 6 m n$ with $d=16$ and $m = n/8$.
           Bars are annotated with the observed runtime (ms).}
  \label{fig:triton_sd_kde_nd_util}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.8\linewidth]{../triton-large-util.pdf}
  \caption{Utilization of the Triton SD-KDE kernel for large $n_{\text{train}}$
           (powers of two up to $2^{22}$).  Labels show the observed runtime
           for each data size; error bars are omitted because a single seed is
           used per point.}
  \label{fig:triton_large_util}
\end{figure}

\section{Performance tuning}

We performed a sweep over the Triton launch parameters to improve utilization
for the $k = 32\text{k}$ case (with $k/8$ queries).  Specifically we varied:
\begin{itemize}
  \item $BLOCK\_M \in \{32, 64, 128, 256\}$,
  \item $BLOCK\_N \in \{32, 64, 128, 256\}$,
  \item $num\_warps \in \{1, 2, 4, 8\}$,
  \item $num\_stages \in \{1, 2, 4\}$,
\end{itemize}
and selected the combination that minimized runtime.  For this workload we
found that $BLOCK\_M=64$, $BLOCK\_N=128$, $num\_warps=1$, and $num\_stages=2$
gave the best overall performance, increasing measured FLOP utilization by
more than $2\times$ relative to the initial settings.  The same sweep can be
repeated for different problem sizes if further tuning is needed.

\end{document}
